要看的论文
- [Supporting Clustering with Contrastive Learning](https://aclanthology.org/2021.naacl-main.427.pdf)
- 
## 01_Synergizing Large Language Models and Pre-Trained Smaller Models for Conversational Intent Discovery
[2024.findings-acl.840.pdf](https://aclanthology.org/2024.findings-acl.840.pdf)
### 摘要
- 提出**SynCID**，它利用了 LLM 的深刻语义理解以及 SLM 的动作敏捷性。通过利用 LLM 来优化话语和意图标签中现有的话语，SynCID 显著**增强语义深度**，随后在 SLM 的特征空间中重新调整这些丰富的描述符，以**纠正集群失真**并促进对表示的稳健学习。一个关键优势是它能够及早识别新意图，这是成功部署对话代理的关键方面。此外，SynCID 还利用 LLM 的上下文学习优势**为新意图生成标签**。对各种数据集的全面评估表明，它的性能优于传统的 CID 方法。
- <span style="color: red">我的总结</span>：提出SynCID，使用LLM优化丰富话语表示，增强语义深度；对齐话语空间和意图标签空间；利用LLM为新意图生成标签。
### 引言
- **研究现状**
	- 从前：close-world intent classification task，但现实new intents continuously emerge
	- 有监督：得到意图表示，聚类
	- 半监督：利用可用的标记数据对 SLM 进行初始预训练，然后在未标记的话语上使用伪监督信号微调这些模型以进行意图识别
- **挑战**：
	- **泛化能力**：难以捕获意图的全部范围并准确建模已知的标签语义。这种限制不仅使他们偏向于现有的意图类别，而且还损害了他们及早检测新意图的能力，这是自适应对话代理的关键能力。
	- **无法标记新的意图**：因为 CID 模型固有的判别性架构在识别和标记新出现的意图方面存在不足
- <span style="color: red">LLM</span>：LLM 的**上下文长度限制**了它们在 CID 中的直接使用，这需要包含数千个话语。虽然可以将用户话语与特定于任务的提示集成，以从 LLM 中请求意图标签，但这种提示方法可能会在没有足够控制的情况下生成意图标签，从而导致不可预测和无指导性的结果
- **本文**：
	- SynCID 采用**LLM 的双重提示机制**来优化话语和已知的意图标签，从而**提高意图描述符的语义精度**。这个改进过程，以 LLM 的细微差别为依据，不仅阐明了意图表示，还为更有效的学习奠定了基础。
	- 在此之后，通过**对比学习**对 SLM 进行训练，以将话语的语义空间与意图描述符的语义**空间对齐**。这种创新的对齐策略极大地减少了集群失真，并提高了系统早期检测和标记新意图的能力，解决了当前 CID 方法的主要局限性。通过从新形成的意图集群中选择有限数量的接近中心的话语，以**使用 LLM 进行上下文学习**，SynCID 实现了**精确的意图标记**。
### 相关工作
- **Previous work**
	- 无监督的 CID 方法都无法在学习表示和聚类用户意图中充分利用监督信号
	- 半监督：通过利用来自预训练 SLM 的伪监督信号显着增强了 CID。然而，它经常面临与这些伪监控信号的质量相关的问题  
- **The synergyize between LLMs and SLMs**
	- 使用 LLM 创建新的高质量数据，用于训练下游 SLM，使它们能够实现竞争性能。然而，CID 中的这种方法可能会**无意中改变话语的语义或引入噪声**，从而挑战准确的意图识别。
	- 利用 LLM 生成特定于任务的标签和详细解释，促进了 SLM 的推理任务训练。然而，所有这些方法主要**依赖于使用一组有限的标签**来注释数据或训练生成模型来对齐 LLM 中的知识，这在 CID 中并不适用。
### 方法
**Syn-CID Framework**
1. **LLM-based descriptor generator
	- 此阶段旨在利用 LLM 将话语和已知意图标签概括为简洁、准确的意图描述符，消除话语中不相关的内容，同时丰富已知意图标签的语义。
	- 分为已知意图（带标签）$P_l$和无标签数据的提示词$P_u$
	- 对于所有话语，得到$d^u$，
2. **Space alignment(SA): 以促进 LLM 和 SLM 之间的协同作用
	- 使用**对比学习**直接对齐话语和意图的**语义空间**
		- 对于所有话语：话语和其对应的描述话语的特征表示为正样本对，使用无监督对比损失函数
		- 对于有标签话语（能利用到监督信号），使用监督对比损失函数；
		- 对于有标签话语，计算标准交叉熵损失，以调节 SynCID 的训练。它优化了SLM，将话语的目标意向类与所有已知的意向类区分开来，从而增强了对话语表示的学习。
	- 带有**邻近过滤**的 SA，它利用意图描述符来优化话语之间的邻里关系，过滤掉噪音并促进紧凑意图集群的形成。
		- **存在问题**：这些学习的话语表示不可避免地会受到使用无监督对比损失或模型的有限理解能力的话语噪声的影响。此外，虽然使用 LLM 生成的意图描述符可以促进表征的学习，但仍然存在模型被 LLM 产生的潜在错误信息误导的风险。
		- **邻近过滤的使用动机**：为了更有效地协同 LLM 与 SLM 并放大 LLM 对识别意图的洞察力，我们通过实施邻里言语过滤进一步增强了 SynCID，旨在使言语的语义空间与 LLM 的意图描述符之间更加一致。
3. **Intent label generation
	- 然而，为帐篷集群中新发现的种类分配准确的标签仍然具有挑战性。SynCID 通过利用 LLM 的上下文学习功能为新的意图集群生成合适的标签来解决这个问题。具体来说，我们设计了一个标签生成提示 （LG_Prompt） 用于从 LLM 中提取标签
	- 
**操作流程**
- 利用LLM对标签数据和无标签数据分别处理，生成意图描述，并得到（重新定义）新的训练数据集
- 将这些话语、话语描述、意图描述输入到SLM中得到描述特征表示和语义特征表示
- （对比损失对齐）计算所有话语的无监督对比损失、有标签话语的监督对比损失和交叉熵损失，加权求和作为总体损失，更新SLM模型参数，优化预训练模型，从而能更好地提取特征表示
- （邻近过滤对齐）首先计算分别得到邻近话语集和邻近意图描述集，然后过滤临近话语集合中相应意图描述不在邻近意图描述集中的话语，得到最终的邻近话语集；之后计算对比损失函数更新参数、优化模型；而且会在训练几轮之后不断更新邻近话语集合和邻近意图描述集合。
- 至此，预训练模型就训练完成了。之后是使用模型输出的特征表示进行聚类，聚类仍依赖传统算法（如K-means），但标签生成依赖LLM为每个新意图簇生成标签（基于簇中心话语）
### 实验
### 我的理解
- 使用LLM扩充数据增强语义深度，使用邻近过滤对齐过滤噪音、纠正集群失真
- 使用LLM为每个新意图簇生成标签
### 问题
- 对话意图发现CID
- SLMs
- 实验结果相差也太大了吧？
- 语义空间
- 话语表示和意图表示
- 判别表示学习
- 虽然作者对每个步骤都说了原因，但是我还是觉得很玄乎，总不能直接提出吧？是做了实验不断验证总结吗？
### 总结

## 02_Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery
[2024.naacl-long.434.pdf](https://aclanthology.org/2024.naacl-long.434.pdf)
### 摘要
- 我们建议将 LLM 的反馈整合到主动学习范式中。具体来说，我们的方法创新性地采用不确定性传播从高不确定性区域选择数据样本，然后通过基于比较的提示方案使用 LLM 进行标记。这不仅简化了标记任务，还提高了识别新类别的准确性。
- 此外，还引入了软反馈传播机制，以最大限度地减少不准确反馈的传播。
- 在各种数据集上的实验证明了我们框架的有效性和通用性，以名义的平均成本显着改进了基线模型。
### 引言
- **问题定义**：GCD 通用品类发现
- **现存问题**：这种对熟悉数据的过度拟合限制了 GCD 的范围，使其无法完全接受它所预期的开放世界设置。**（泛化能力）
- **LLM**：他们理解和生成细微语言模式的能力使他们有望补充 GCD 中新类别的监督。然而，在 GCD 中直接应用 LLM（通常涉及处理和聚类数千个样本）带来了巨大的挑战。LLM 的密集计算需求可能会导致**数据隐私、高延迟和成本增加等问题**，这在大规模 GCD 场景中尤其成问题。
- **LLM带来新的挑战**：为了规避上述挑战，将 LLM 集成到主动学习框架中提供了一种实用且有效的解决方案。这种方法有选择地使用 LLM 来提供监督信号，尤其是在数据最不确定或类别新颖的情况下。然而，这种整合带来了新的挑战：优化使用 LLM 以**确保成本和时间效率**，以及至关重要的是，**确保 LLM 提供的反馈的可靠性**。需要有效的策略来降低传播 LLM 错误反馈的风险。
- **本文工作**
	- 为了应对这些挑战，我们提出了一个新的框架，让 GCD 积极地从具有不确定性传播的 LLM 中学习，称为 **ALUP**。
	- 我们首先采用不确定性传播策略，该策略系统地识别高不确定性区域的数据样本——这些是模型最没有信心的区域，因此，LLM input可能是最有益的领域。然后，使用 LLM 通过复杂的基于比较的提示技术对选定的样本进行标记。这种方法利用了 LLM 的比较优势，使它们更容易提供准确的反馈，尤其是对于新的和复杂的类别。
	- 为了进一步增强我们的方法，我们采用了软标签传播机制。这种机制会小心地将 LLM 生成的反馈扩展到相似的相邻样本，从而有效地放大每个 LLM 查询的价值，同时最大限度地降低传播门控错误的风险。
- **贡献总结**
	-  • 我们开发了一个创新的主动学习框架ALUP，整合了 LLM 对 GCD 的反馈，解决了对新数据类别的有限感知的挑战。
	-  • 我们将基于不确定性区域的数据选择和基于比较的 LLM 提示相结合，通过软传播显著提高了 GCD 的准确性和效率。
	-  • 实验表明，在不同数据集中，与传统 GCD 方法相比，它有显著的改进，肯定了 ALUP 的有效性和资源效率。
### 相关工作
- 无监督方法 / 半监督方法
- **传统主动学习(AL)**
- 
### 方法
**Framework**
- **Uncertainty Propagation
	- **目标**：选择代表高不确定性区域的信息量最大的未标记样本
	- 计算模型预测概率矩阵：预训练模型提取话语的特征表示，使用K-means定位簇中心，使用t-分布计算样本i分配到类别j中的概率
	- 使用熵**计算每个样本的不确定度**，但是直接使用这个分数会导致**次优结果**，使用欧几里得距离找到**k-nearest neighbour**，使用RBF函数计算样本和邻近样本之间的相似度，然后根据公式对每个样本的不确定性得分进行**修正**，得到最终的不确定性得分
	- **经过几轮不确定性分数属性，我们得到最终的不确定性分数**
	- 在每个类别中选择得分最高的那一个样本，得到集合Q，然后为Q中的每一个样本应用LLM得到反馈，获取这些样本的伪标签
- **Comparison-based Promting
	- **使用动机**：但是，由于新出现的类别的类别标签仍然未知，因此要求 LLM 直接为每个选定的样本生成一个全新的标签是不可行的。为了克服这个问题，我们从聚类的角度设计了一种基于比较的提示方法，该方法提示 LLM 通过将样本与代表不同类别的其他样本进行比较来对样本进行分类。这种 CP 方法需要为每个类别聚类选择一个代表反感样本。
	- p 是用于比较的代表性样本数。在我们的实验中，对于 Q 中的每个$x^q_i$，我们凭经验将 p = |Q|/2 个与 xq i 接近的代表性样本放入提示符中。通过这种设计，我们可以有效地利用 LLM 将选定的样本分类为相应的类别，表示为 Q = {xqi，yLLM i }K i=1，从而绕过未知分类的显式标签要求。
- **Soft Feedback Propagation
	- 通过使用 CP 方法查询 LLM，我们可以为选定的未标记样本赋予它们各自的伪标签，以增强 GCD 模型以识别新类别。然而，部分和完全 LLM 增强的 GCD 模型之间仍然存在性能差距。鉴于未标记样本的选择是基于它们的模型预测不确定性和相邻不确定性，并且彼此靠近分布的样本更有可能共享同一类别，因此我们提出了一种软反馈传播机制，以将 LLM 生成的伪标签传播到它们的相似邻居之间，放大来自 LLM 的反馈的效用，而无需任何额外费用。
	- 在从 LLM 获得 Q 中选定的 unlabeled 样本的伪标签并通过 SFP 传播这些标签后，我们使用监督对比学习损失更新模型

**我的理解**
- 首先通过计算每个样本的不确定度，从每个类别中选择不确定性得分最高的样本，这些样本的集合就是高不确定性区域，然后在高不确定性区域（获益大）基于比较提示应用LLM获取伪标签；然后使用提出的软反馈传播机制将LLM生成的伪标签传播到他们的相似邻居之间。通过上述操作能够发挥LLM的优势，得到预测标签概率矩阵。然后使用监督对比损失更新预训练模型参数，获得更好的意图特征表示。预训练模型优化完成之后，和传统方法无异，使用K-means聚类，识别分类已知意图和未知意图。
- 如果不先选择高不确定性区域直接使用LLM，会使得成本极高，论文的做法能够规避LLM带来的挑战。这是论文核心创新点。
### 实验
### 问题
### 总结
- 次优结果


## 03_Open Intent Discovery through Unsupervised Semantic Clustering and Dependency Parsing
2021
- （1） 我们提出了一个灵活的开放意图发现框架，它可以生成人类可解释的意图，并以无监督的方式用高 F1 标记话语;
- （2） 我们开发了一种基于规则的方法，用于使用依赖关系解析自动生成 intent 标签;
- （3） 我们使用新提出的平衡分数指标在确定平衡数据集的最佳聚类数时增强了标准 K-means 聚类。
## 04_Deep Open Intent Classification with Adaptive Decision Boundary
[2012.10209](https://arxiv.org/pdf/2012.10209)

**Open Intent Discovery**: 我们将开放意图分类视为n+1个类别的类别分类任务，我们的目标是在识别第 n+1类开放意图的同时，将 n 类已知意图正确分类为相应的类。[1709.08716](https://arxiv.org/pdf/1709.08716) / [[1906.00434] 具有边距损失的深度未知意图检测](https://arxiv.org/abs/1906.00434)
### 摘要
- 开放意图分类在对话系统中是一项具有挑战性的任务。一方面，它应该保证已知意图识别的质量。另一方面，它需要在没有先验知识的情况下检测开放 （未知） 意图。当前模型在寻找适当的决策边界以平衡已知意图和开放意图的性能方面受到限制。
- 在本文中，我们提出了一种后处理方法来学习开放意图分类的自适应决策边界 （ADB）。我们首先利用 labeled 已知意图样本来预训练模型。然后，我们借助训练有素的特征自动学习每个已知类别的自适应球面决策边界。具体来说，我们提出了一个新的损失函数来平衡经验风险和开放空间风险。我们的方法不需要开放意图样本，也无需修改模型架构。此外，我们的方法出奇地不敏感，标记的数据较少，已知意图较少。对三个基准数据集的广泛实验表明，与最先进的方法相比，我们的方法产生了显着的改进。这些代码在 https://github.com/thuiar/Adaptive-Decision-Boundary 发布。
### 引言
- **开放意图分类**
	- 大多数现有方法都需要设计特定的分类器来识别开放类，并且公共分类器的形式不佳，很大程度上取决于决策条件。
	- 这些方法中的大多数都需要负样本来确定合适的决策条件。手动选择最优决策条件也是一个复杂且耗时的过程，这在真实场景中并不适用。
- 本文工作
	- 为了解决这些问题，我们使用已知意图作为先验知识，并提出了一种新的后处理方法来学习 open intent 分类的自适应决策边界 （ADB）。
	- 首先从 BERT 中提取意图表示。
	- 然后，我们在 softmax loss 的监督下对模型进行预训练。我们为每个已知类定义质心，并假设每个已知类的意图特征都被约束在一个封闭的球区域中。
	- 接下来，我们的目标是学习球面面积的半径以获得决策边界。
		- 具体来说，我们使用标准正态分布初始化边界参数，并使用可学习的激活函数作为投影来获得每个决策边界的半径。
		- 合适的决策边界应满足两个条件。一方面，它们应该足够宽泛，以尽可能多地包围已知的意图样本。另一方面，它们需要足够紧密，以防止打开的 intent 样本被识别为已知 intent。
		- 为了解决这些问题，我们提出了一种新的损失函数，它通过平衡开放空间风险和经验风险来优化边界参数（Scheirer 等人，2013 年）。决策边界可以自动学习适应边界损失的意图特征空间，直到平衡。
- 工作总结
	- 提出了一种新的开放分类后处理方法，无需事先了解 Open Intent。
	- 其次，我们提出了一种新的损失函数，以自动学习适应特征空间的严格决策边界。据我们所知，这是首次尝试采用深度神经网络来学习开放分类的自适应决策边界。
	- 第三，对三个具有挑战性的数据集进行的广泛实验表明，我们的方法始终产生更好和更多的结果
### 相关工作

### 方法
**监督学习**，训练阶段只用到了有标签数据
- 意图表示
	- bert特征提取。生成句子的高层语义表示$x_i \in R^H$
	- 全连接层增强特征，得到意图表示$z_i \in R^D$
- 预训练
	- 使用标准的softmax损失函数对已知意图作为先验知识进行预训练，优化模型参数以提取区分性特征
	- 冻结参数：在后续边界学习阶段，冻结Bert的大部分参数，仅微调最后一层， 避免特征空间剧烈变化
- 自适应决策边界学习
	- 质心计算：对每个已知类别K，计算其样本特征的平均向量作为质心$c_k$
	- 边界参数化
		- 初始化可学习的半径参数，通过Softplus函数映射为非负半径值
		- 确保半径自适应特征空间，避免手动调参
	- 边界损失函数：
		- 定义边界损失，平衡经验风险（已知类样本被包含）和开放空间风险（开放类样本被排除）
		- 更新边界半径：梯度下降法
- 使用决策边界的开放分类
	- 决策规则：测试时，样本若到所有已知类质心的距离均超过对应半径，则判定为开放意图；否则归类到最近已知类
	- 对应的公式：
### 实验
- 不同数据集 / 已知类别比例 / 标记数据比例
### 我的理解
论文属于监督学习，最开始
使用预训练模型得到意图表示，下面的所有步骤都是针对标签数据进行的。然后作者使用标签话语（当然也是已知意图）进行预训练优化模型参数，然后后续仅微调最后一层。先计算K个类别的质心，然后计算样本与质心的距离，定义损失函数，里面涉及到比较第K个类别的半径和这个类别中样本与质心的距离来控制决策边界是扩张还是收缩。还使用softplus映射确保每个类别的半径是正值。总之会根据这个损失函数更新决策边界的半径。多次迭代之后得到最优的模型参数（只有最后一层的参数更新）。现在训练结束，测试集中的数据既有已知意图也有未知意图，作者通过计算每个意图到质心的距离与决策边界比较决定这个意图是已知还是未知，并分配到对应哪个类别。

本文提出了一种**简洁有效的开放意图分类方法**，核心贡献在于**自适应球形决策边界的学习框架**，实验证明其在低资源场景下的优越性。然而，方法对特征分布和边界形状的假设可能限制其普适性，且实验对比和理论深度有待加强。​**适合作为工程导向的解决方案**，但在复杂开放类检测任务中需进一步验证边界假设的合理性。

**未来方向**:  
1. 探索非球形边界（如流形学习）以捕捉复杂类内结构。
2. 结合对比学习增强预训练特征判别性，降低对边界形状的依赖。
3. 在更具挑战性的开放类分布（如对抗样本、语义相似意图）上测试方法鲁棒性。

## 待办
- [x] 开放意图检测和NID的区别，主要整理<a href="https://github.com/thuiar/OKD-Reading-List">论文列表</a>
- [x] 对方向定义区分清楚后，对论文列表里的各个方向的论文都再做个区分，重点是技术路线这里
- [ ] 以上两点都要做笔记，汇总到总结里
- [ ] 总结里没写完的，再整理完善一下
- [ ] 至此，基本能完整输出初版了。然后是大致思考一下类型方向，如果要写综述的话，应该要怎么写？

## 05_
## 感想与总结
### 0324周一
- 下午躺了，晚上做大数据分析第七章的图了
### 0325周二
- GitHub仓库已经熟悉很多了，笔记也在慢慢规范化
- 看了半篇论文，不是，感觉结合LLM的话，就这？就这？就纯纯提示词工程呗？
- 下午做大数据分析的图去了，md编辑能力又上涨了一点点
- 编辑公众号了
### 0326周三
- 组会看了昨天的后半篇论文
- 新开了一篇LLM的论文，看了半篇，因为发现这两篇都给看串了，不想看了
- 公众号发了
### 0327周四
- 上午躺了：洗澡洗衣服收拾东西三件套
- 下午：学的很烦，处于一个重新恢复学习的痛苦期；最难的是要怎么汇报呢（好像知道了但是总结出来好像水平还不够，而且论文不仅串、还会忘，不想重新看）？
- 晚上：已经有总结初版了，主要是探索吧，晚上没学太长时间
### 0328周五
- 上午：还是探索吧，没有具体任务，又卡住了
- 下午偏微分（没看）
- 晚上再说
### 0329周六
- 在身体痛苦面前，意志力很难干过去
- 但是睡前弄清楚了第一个问题：NID v.s. OID

### 0330周日
- 上午躺了，昨晚上失眠
- 下午寄了，